{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHLcriKWLRe4"
      },
      "source": [
        "# Lab 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X58hOMTUH-w"
      },
      "outputs": [],
      "source": [
        "# Import the libraries we'll use below.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nNOD-Z7SzAq"
      },
      "source": [
        "## Data as matrices\n",
        "Data usually comes in the form of matrices. The Python Numpy library makes it easy to manipulate matrices efficiently. See the [Numpy Tutorial](https://docs.scipy.org/doc/numpy/user/quickstart.html) for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWlmuAMwTZ3P"
      },
      "outputs": [],
      "source": [
        "# Print these to make sure you understand what is being generated.\n",
        "A = np.array([1, 2, 3])\n",
        "B = np.arange(1, 13).reshape(3, 4)\n",
        "C = np.ones((2, 3))\n",
        "D = np.eye(3)\n",
        "\n",
        "print(A)\n",
        "print(B)\n",
        "print(C)\n",
        "print(D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4wvvzKoUIAN"
      },
      "source": [
        "---\n",
        "### Exercise 1: Matrix manipulation (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgVKvoK6t90a"
      },
      "source": [
        "Perform the following computations using numpy functions and print the results. Note that the `*` operator implies matrix multiplication -- make sure the dimensions align!\n",
        "1. 2A + 1\n",
        "2. Sum the rows of B\n",
        "3. Sum the columns of B\n",
        "4. Number of elements of B greater than 5\n",
        "5. C + C\n",
        "6. A * B\n",
        "7. (B * B) - D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJtwrjdO6TbS"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "#1.\n",
        "print(2*A+1)\n",
        "\n",
        "#2.\n",
        "row_n = np.shape(B)[0]\n",
        "col_n = np.shape(B)[1]\n",
        "\n",
        "for i in range(row_n):\n",
        "  sum = 0\n",
        "  for j in range(col_n):\n",
        "    sum = sum + B[i][j]\n",
        "\n",
        "  print('sum of the '+ str(i) + ' row is ' + str(sum))\n",
        "  \n",
        "#3. \n",
        "for j in range(col_n):\n",
        "  sum = 0\n",
        "  for i in range(row_n):\n",
        "    sum = sum + B[i][j]\n",
        "\n",
        "  print('sum of the '+ str(i) + ' column is ' + str(sum))  \n",
        "\n",
        "#4.\n",
        "n = 0\n",
        "for i in range(row_n):\n",
        "  for j in range(col_n):\n",
        "    if B[i][j] > 5:\n",
        "      n = n+1 \n",
        "print(n)\n",
        "\n",
        "#5.\n",
        "print(C+C)\n",
        "\n",
        "#6.\n",
        "\n",
        "print(np.dot(A,B))\n",
        "\n",
        "#7.\n",
        "print(np.dot(B, B.T)-D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfaWxhXUt90b"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbCRG2-uUKCT"
      },
      "source": [
        "## Data for Supervised Learning\n",
        "Supervised learning is all about learning to make predictions: given an input $x$ (e.g. home square footage), can we produce an output $\\hat{y}$ (e.g. estimated value) as close to the actual observed output $y$ (e.g. sale price) as possible. Note that the \"hat\" above $y$ is used to denote an estimated or predicted value.\n",
        "\n",
        "Let's start by generating some artificial data. We'll create a vector of inputs, $X$, and a corresponding vector of target outputs $Y$. In general, we'll refer to invidual examples with a lowercase ($x$), and a vector or matrix containing multiple examples with a capital ($X$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ulmn_bFdU87t"
      },
      "outputs": [],
      "source": [
        "def create_1d_data(num_examples=10, w=2, b=1, random_scale=1):\n",
        "  \"\"\"Create X, Y data with a linear relationship with added noise.\n",
        "\n",
        "  Args:\n",
        "    num_examples: number of examples to generate\n",
        "    w: desired slope\n",
        "    b: desired intercept\n",
        "    random_scale: add uniform noise between -random_scale and +random_scale\n",
        "\n",
        "  Returns:\n",
        "    X and Y with shape (num_examples)\n",
        "  \"\"\"\n",
        "  X = np.arange(num_examples)\n",
        "  np.random.seed(4)  # consistent random number generation\n",
        "  deltas = np.random.uniform(low=-random_scale, high=random_scale, size=X.shape)\n",
        "  Y = b + deltas + w * X\n",
        "  return X, Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qJg0IiYVJ8U"
      },
      "outputs": [],
      "source": [
        "# Create some artificial data using create_1d_data.\n",
        "X, Y = create_1d_data(num_examples=20, w=2, b=1, random_scale=2)\n",
        "plt.scatter(X, Y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6coKbXSpXOz"
      },
      "source": [
        "---\n",
        "### Exercise 2: Models for Data (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX8tN0PIt90e"
      },
      "source": [
        "A model is a function that takes an input $x$ and produces a prediction $\\hat{y}$.\n",
        "\n",
        "Let's consider two possible models for this data:\n",
        "1. $M_1(x) = x+5$ \n",
        "2. $M_2(x) = 2x+1$\n",
        "\n",
        "Compute the predictions of models $M_1$ and $M_2$ for the values in $X$. These predictions should be vectors of the same shape as $Y$. Then plot the prediction lines of these two models overlayed on the \"observed\" data $(X, Y)$. Use [plt.plot()](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html) to draw the lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHIY5kNXUIAP"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "x = np.arange(10)\n",
        "M1 = x + 5\n",
        "M2 = 2*x + 1\n",
        "\n",
        "print(x)\n",
        "\n",
        "plt.plot(x, M1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.arange(10)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "rtAUmnMGT-uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1+1"
      ],
      "metadata": {
        "id": "2YETsXehVVrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0i-e4m1t90f"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH-0soZiWx9x"
      },
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "How good are our models? Intuitively, the better the model, the more closely it fits the data we have. That is, for each $x$, we'll compare $y$, the true value, with $\\hat{y}$, the predicted value. This comparison is often called the *loss* or the *error*. One common such comparison is *squared error*: $(y-\\hat{y})^2$. Averaging over all our data points, we get the *mean squared error*:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textit{MSE} = \\frac{1}{|Y|} \\sum_{y_i \\in Y}(y_i - \\hat{y}_i)^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AyY2DpxYLI0"
      },
      "source": [
        "---\n",
        "### Exercise 3: Computing MSE (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HczWfrXDt90f"
      },
      "source": [
        "Write a function for computing the MSE metric and use it to compute the MSE for the two models above, $M_1$ and $M_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCeAfI5mW9sg"
      },
      "outputs": [],
      "source": [
        "def MSE(true_values, predicted_values):\n",
        "  \"\"\"Return the MSE between true_values and predicted values.\"\"\"\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF-x9DI2ZOKq"
      },
      "outputs": [],
      "source": [
        "print ('MSE for M1:', MSE(Y, M1))\n",
        "print ('MSE for M2:', MSE(Y, M2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJEO0eYzt90g"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDiy3OZwZlwj"
      },
      "source": [
        "## Generalization\n",
        "\n",
        "Our data $(X, Y)$ represents just a sample of all possible input-output pairs we might care about. A model will be useful to the extent we can apply it to new inputs. Consider the more complex model below, which appears to produce a much smaller mean squared error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns1siZ9DZvSY"
      },
      "outputs": [],
      "source": [
        "# Fit an 8-th degree polynomial to (X, Y). See np.polyfit for details.\n",
        "polynomial_model_coefficients = np.polyfit(X, Y, deg=8)\n",
        "polynomial_model = np.poly1d(polynomial_model_coefficients)\n",
        "M3 = polynomial_model(X)\n",
        "fig = plt.scatter(X, Y)\n",
        "plt.plot(X, M3, '-k')\n",
        "print ('MSE for M3:', MSE(Y, M3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2m9YmLMZ1EV"
      },
      "source": [
        "---\n",
        "### Exercise 4: Generalization (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdhqVrt7t90h"
      },
      "source": [
        "Explain whether you expect $M_3$ to be better than $M_2$ at predicting the labels for new unseen inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Zpx79_aQEC"
      },
      "source": [
        "*Writen answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9EH9D7Faf9n"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hIdZHngdrET"
      },
      "source": [
        "## Review\n",
        "\n",
        "* In **Supervised Machine Learning**, we must start with data in the form $(X,Y)$ where $X$ are the inputs and $Y$ are the output labels.\n",
        "* A **model** is a function that maps an input $x$ to an output $y$. The model's output is referred to as a **prediction**, denoted by $\\hat{y}$.\n",
        "* We **evaluate** predictions by comparing them to the true labels. This measurement is called a **loss** or **error**. For real-valued data, **mean squared error** is a common metric.\n",
        "* A model is only as good as its ability to **generalize** to new examples."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "copyright",
        "xxOhpvdW6TbX",
        "exercise-1-key-1",
        "43ZTSJEc526U",
        "exercise-5-key-1",
        "ubHispCAA_5u",
        "exercise-6-key-1",
        "5p1IvWjfEjqm",
        "exercise-9-key-1"
      ],
      "name": "01 Introduction.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}